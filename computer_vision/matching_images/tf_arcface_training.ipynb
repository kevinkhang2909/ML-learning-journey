{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f3a010a0-1e28-42e1-be3b-5dbe8ab3f85c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import tensorflow as tf\n",
    "import tensorflow_addons as tfa\n",
    "\n",
    "from PIL import Image\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import KFold, train_test_split\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from func import path, get_data, path_img\n",
    "from func_keras import get_model, seed_everything\n",
    "import tensorflow as tf\n",
    "import efficientnet.keras as efn\n",
    "import math\n",
    "from sklearn.neighbors import NearestNeighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d95538fa-3b1c-423d-aa3f-0e5580286462",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>posting_id</th>\n",
       "      <th>image</th>\n",
       "      <th>image_phash</th>\n",
       "      <th>title</th>\n",
       "      <th>label_group</th>\n",
       "      <th>filepath</th>\n",
       "      <th>target</th>\n",
       "      <th>title_edit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>train_129225211</td>\n",
       "      <td>0000a68812bc7e98c42888dfb1c07da0.jpg</td>\n",
       "      <td>94974f937d4c2433</td>\n",
       "      <td>Paper Bag Victoria Secret</td>\n",
       "      <td>249114794</td>\n",
       "      <td>C:\\Users\\PC\\OneDrive - Seagroup\\computer_vison...</td>\n",
       "      <td>[train_2278313361, train_129225211]</td>\n",
       "      <td>paper bag victoria secret</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>train_3386243561</td>\n",
       "      <td>00039780dfc94d01db8676fe789ecd05.jpg</td>\n",
       "      <td>af3f9460c2838f0f</td>\n",
       "      <td>Double Tape 3M VHB 12 mm x 4,5 m ORIGINAL / DO...</td>\n",
       "      <td>2937985045</td>\n",
       "      <td>C:\\Users\\PC\\OneDrive - Seagroup\\computer_vison...</td>\n",
       "      <td>[train_3423213080, train_3386243561]</td>\n",
       "      <td>double tape 3m vhb 12 mm x 4,5 m original / do...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>train_2288590299</td>\n",
       "      <td>000a190fdd715a2a36faed16e2c65df7.jpg</td>\n",
       "      <td>b94cb00ed3e50f78</td>\n",
       "      <td>Maling TTS Canned Pork Luncheon Meat 397 gr</td>\n",
       "      <td>2395904891</td>\n",
       "      <td>C:\\Users\\PC\\OneDrive - Seagroup\\computer_vison...</td>\n",
       "      <td>[train_3803689425, train_2288590299]</td>\n",
       "      <td>maling tts canned pork luncheon meat 397 gr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>train_2406599165</td>\n",
       "      <td>00117e4fc239b1b641ff08340b429633.jpg</td>\n",
       "      <td>8514fc58eafea283</td>\n",
       "      <td>Daster Batik Lengan pendek - Motif Acak / Camp...</td>\n",
       "      <td>4093212188</td>\n",
       "      <td>C:\\Users\\PC\\OneDrive - Seagroup\\computer_vison...</td>\n",
       "      <td>[train_3342059966, train_2406599165]</td>\n",
       "      <td>daster batik lengan pendek - motif acak / camp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>train_3369186413</td>\n",
       "      <td>00136d1cf4edede0203f32f05f660588.jpg</td>\n",
       "      <td>a6f319f924ad708c</td>\n",
       "      <td>Nescafe \\xc3\\x89clair Latte 220ml</td>\n",
       "      <td>3648931069</td>\n",
       "      <td>C:\\Users\\PC\\OneDrive - Seagroup\\computer_vison...</td>\n",
       "      <td>[train_921438619, train_3369186413]</td>\n",
       "      <td>nescafe \\xc3\\x89clair latte 220ml</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         posting_id                                 image       image_phash  \\\n",
       "0   train_129225211  0000a68812bc7e98c42888dfb1c07da0.jpg  94974f937d4c2433   \n",
       "1  train_3386243561  00039780dfc94d01db8676fe789ecd05.jpg  af3f9460c2838f0f   \n",
       "2  train_2288590299  000a190fdd715a2a36faed16e2c65df7.jpg  b94cb00ed3e50f78   \n",
       "3  train_2406599165  00117e4fc239b1b641ff08340b429633.jpg  8514fc58eafea283   \n",
       "4  train_3369186413  00136d1cf4edede0203f32f05f660588.jpg  a6f319f924ad708c   \n",
       "\n",
       "                                               title  label_group  \\\n",
       "0                          Paper Bag Victoria Secret    249114794   \n",
       "1  Double Tape 3M VHB 12 mm x 4,5 m ORIGINAL / DO...   2937985045   \n",
       "2        Maling TTS Canned Pork Luncheon Meat 397 gr   2395904891   \n",
       "3  Daster Batik Lengan pendek - Motif Acak / Camp...   4093212188   \n",
       "4                  Nescafe \\xc3\\x89clair Latte 220ml   3648931069   \n",
       "\n",
       "                                            filepath  \\\n",
       "0  C:\\Users\\PC\\OneDrive - Seagroup\\computer_vison...   \n",
       "1  C:\\Users\\PC\\OneDrive - Seagroup\\computer_vison...   \n",
       "2  C:\\Users\\PC\\OneDrive - Seagroup\\computer_vison...   \n",
       "3  C:\\Users\\PC\\OneDrive - Seagroup\\computer_vison...   \n",
       "4  C:\\Users\\PC\\OneDrive - Seagroup\\computer_vison...   \n",
       "\n",
       "                                 target  \\\n",
       "0   [train_2278313361, train_129225211]   \n",
       "1  [train_3423213080, train_3386243561]   \n",
       "2  [train_3803689425, train_2288590299]   \n",
       "3  [train_3342059966, train_2406599165]   \n",
       "4   [train_921438619, train_3369186413]   \n",
       "\n",
       "                                          title_edit  \n",
       "0                          paper bag victoria secret  \n",
       "1  double tape 3m vhb 12 mm x 4,5 m original / do...  \n",
       "2        maling tts canned pork luncheon meat 397 gr  \n",
       "3  daster batik lengan pendek - motif acak / camp...  \n",
       "4                  nescafe \\xc3\\x89clair latte 220ml  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# input\n",
    "df = get_data(path / 'train.csv', path_img)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2ef29217-40f2-4741-860a-d8ef60f4b838",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "train_filenames = tf.io.gfile.glob([str(path) + '/train_record/*.*'])\n",
    "# test_filenames = tf.io.gfile.glob([str(path) + '/test_images/*.*'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "69d08726-ef5a-4f63-943c-9653b748e893",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use correct image size with pretrained model\n",
    "IMAGE_SIZE = (300, 300)\n",
    "# Train-test-split size\n",
    "TRAIN_SIZE = 0.8\n",
    "# Initial learning rate\n",
    "LR = 0.001\n",
    "# ArcFace must assume a certain number of classes to optimize loss. May get better results on test set with higher N_CLASSES\n",
    "N_CLASSES = df['label_group'].nunique()\n",
    "AUTO = tf.data.experimental.AUTOTUNE\n",
    "SEED = 42\n",
    "\n",
    "EPOCHS = 30\n",
    "BATCH_SIZE = 4\n",
    "STEPS_PER_EPOCH = len(df) * TRAIN_SIZE // BATCH_SIZE\n",
    "cosine_lr_fn = tf.keras.experimental.CosineDecay(LR, 3*STEPS_PER_EPOCH*10)\n",
    "\n",
    "# Function to seed everything\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "04e64b91-ed32-47f9-8824-7d06256ecc27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ArcFace parameters\n",
    "# s: norm of input feature\n",
    "# m: margin, Original paper states that m=0.5 gives best results. I found this variable to have the strongest effect when calculating final f1 score\n",
    "params = {\n",
    "    'm': 0.0001, \n",
    "    's': 15\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1b7cf784-9915-4dab-b601-009da9dc978d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to augment data\n",
    "# As data was serialized to TFRecords, I directly convert TFRecords to datasets and thus cannot use Keras ImageDataGenerator\n",
    "def data_augment(posting_id, image, label_group, matches):   \n",
    "    rotate = tf.random.uniform(shape=(), minval=-0.1*np.pi, maxval=0.1*np.pi)\n",
    "    image = tfa.image.rotate(image, rotate, interpolation='bilinear', fill_mode='constant')\n",
    "    shear_x = tf.random.uniform(shape=(), minval=-0.2, maxval=0.2)\n",
    "    shear_y = tf.random.uniform(shape=(), minval=-0.2, maxval=0.2)\n",
    "    image = tfa.image.transform(image, [1.0, shear_x, 0.0, shear_y, 1.0, 0.0, 0.0, 0.0], interpolation='bilinear', fill_mode='constant')\n",
    "    translate_vec = tf.random.uniform(shape=(2,), minval=-int(0.05*IMAGE_SIZE[0]), maxval=int(0.05*IMAGE_SIZE[0]))\n",
    "    image = tfa.image.translate(image, translate_vec, interpolation='bilinear', fill_mode='constant')\n",
    "    \n",
    "    crop_size = tf.random.uniform(shape=(), minval=int(0.8*IMAGE_SIZE[0]), maxval=int(1.2*IMAGE_SIZE[0]), dtype=tf.int32)\n",
    "    image = tf.image.resize_with_crop_or_pad(image, crop_size, crop_size)  \n",
    "    image = tf.image.resize(image, IMAGE_SIZE)\n",
    "    \n",
    "    image = tf.image.random_brightness(image, 0.10)\n",
    "    image = tf.image.random_hue(image, 0.01)\n",
    "    image = tf.image.random_saturation(image, 0.80, 1.20)\n",
    "    image = tf.image.random_contrast(image, 0.80, 1.20)\n",
    "    image = tf.image.random_flip_left_right(image)\n",
    "    return posting_id, image, label_group, matches\n",
    "\n",
    "# Function to decode images from serialized image data from TFRecords\n",
    "def decode_image(image_data):\n",
    "    image = tf.image.decode_jpeg(image_data, channels = 3)\n",
    "    image = tf.image.resize(image, IMAGE_SIZE)\n",
    "    image = tf.cast(image, tf.float32) / 255.0\n",
    "    return image\n",
    "\n",
    "# Function to read TFRecords\n",
    "def read_tfrec(example):\n",
    "    tfrec_format = {\n",
    "        \"posting_id\": tf.io.FixedLenFeature([], tf.string),\n",
    "        \"image\": tf.io.FixedLenFeature([], tf.string),\n",
    "        \"label_group\": tf.io.FixedLenFeature([], tf.int64),\n",
    "        \"matches\": tf.io.FixedLenFeature([], tf.string)\n",
    "    }\n",
    "\n",
    "    example = tf.io.parse_single_example(example, tfrec_format)\n",
    "    posting_id = example['posting_id']\n",
    "    image = decode_image(example['image'])\n",
    "    label_group = tf.cast(example['label_group'], tf.int32)\n",
    "    matches = example['matches']\n",
    "    return posting_id, image, label_group, matches\n",
    "\n",
    "# Function to create a dataset by reading TFRecords\n",
    "def load_dataset(filenames):\n",
    "    dataset = tf.data.TFRecordDataset(filenames, num_parallel_reads = AUTO)\n",
    "    dataset = dataset.map(read_tfrec, num_parallel_calls = AUTO) \n",
    "    return dataset\n",
    "\n",
    "# Function to reformat dataset for model\n",
    "def arcface_format(posting_id, image, label_group, matches):\n",
    "    return posting_id, {'image': image, 'label': label_group}, label_group, matches\n",
    "\n",
    "# Function to construct dataset\n",
    "def get_dataset(filenames, training=False):\n",
    "    dataset = load_dataset(filenames)\n",
    "    if training:\n",
    "        ignore_order = tf.data.Options()\n",
    "        dataset = dataset.with_options(ignore_order)\n",
    "        dataset = dataset.map(data_augment, num_parallel_calls = AUTO)\n",
    "        dataset = dataset.repeat()\n",
    "        dataset = dataset.shuffle(2048)\n",
    "    dataset = dataset.map(arcface_format, num_parallel_calls = AUTO)\n",
    "    dataset = dataset.batch(BATCH_SIZE)\n",
    "    dataset = dataset.prefetch(AUTO)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "042ffe94-9674-4db4-aaca-30425f2ffe24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into train and validation sets\n",
    "train, valid = train_test_split(train_filenames, shuffle = True, random_state = SEED)\n",
    "train_dataset = get_dataset(train, training=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a99bc4c0-1dbb-4808-acad-2ea1997085c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " image (InputLayer)             [(None, 300, 300, 3  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " efficientnetb3 (Functional)    (None, None, None,   10783535    ['image[0][0]']                  \n",
      "                                1536)                                                             \n",
      "                                                                                                  \n",
      " ge_m_pooling_layer (GeMPooling  (None, 1536)        0           ['efficientnetb3[0][0]']         \n",
      " Layer)                                                                                           \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 512)          786944      ['ge_m_pooling_layer[0][0]']     \n",
      "                                                                                                  \n",
      " batch_normalization (BatchNorm  (None, 512)         2048        ['dense[0][0]']                  \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " label (InputLayer)             [(None,)]            0           []                               \n",
      "                                                                                                  \n",
      " arc_margin_product (ArcMarginP  (None, 11014)       5639168     ['batch_normalization[0][0]',    \n",
      " roduct)                                                          'label[0][0]']                  \n",
      "                                                                                                  \n",
      " softmax (Softmax)              (None, 11014)        0           ['arc_margin_product[0][0]']     \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 17,211,695\n",
      "Trainable params: 17,123,368\n",
      "Non-trainable params: 88,327\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = get_model(params, N_CLASSES, IMAGE_SIZE, cosine_lr_fn)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4c413300-980a-4373-8702-3b9c4314611d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "6850/6850 [==============================] - 803s 114ms/step - loss: 10.4966 - sparse_categorical_accuracy: 1.8248e-04 - val_loss: 10.6343 - val_sparse_categorical_accuracy: 1.0951e-04\n",
      "Epoch 2/30\n",
      "6850/6850 [==============================] - 783s 114ms/step - loss: 9.8873 - sparse_categorical_accuracy: 2.1898e-04 - val_loss: 9.8636 - val_sparse_categorical_accuracy: 1.0951e-04\n",
      "Epoch 3/30\n",
      "6850/6850 [==============================] - 771s 113ms/step - loss: 9.5826 - sparse_categorical_accuracy: 4.7445e-04 - val_loss: 9.7930 - val_sparse_categorical_accuracy: 1.0951e-04\n",
      "Epoch 4/30\n",
      "6850/6850 [==============================] - 766s 112ms/step - loss: 9.3725 - sparse_categorical_accuracy: 0.0019 - val_loss: 9.7186 - val_sparse_categorical_accuracy: 4.3802e-04\n",
      "Epoch 5/30\n",
      "6850/6850 [==============================] - 774s 113ms/step - loss: 9.2725 - sparse_categorical_accuracy: 0.0015 - val_loss: 9.8342 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 6/30\n",
      "6850/6850 [==============================] - 786s 115ms/step - loss: 9.1961 - sparse_categorical_accuracy: 0.0020 - val_loss: 9.7110 - val_sparse_categorical_accuracy: 5.4753e-04\n",
      "Epoch 7/30\n",
      "6850/6850 [==============================] - 785s 115ms/step - loss: 9.1224 - sparse_categorical_accuracy: 0.0021 - val_loss: 9.6099 - val_sparse_categorical_accuracy: 0.0019\n",
      "Epoch 8/30\n",
      "1089/6850 [===>..........................] - ETA: 10:06 - loss: 9.0740 - sparse_categorical_accuracy: 0.0034"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [9]\u001b[0m, in \u001b[0;36m<cell line: 18>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m# Model checkpoint\u001b[39;00m\n\u001b[0;32m     12\u001b[0m checkpoint \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mcallbacks\u001b[38;5;241m.\u001b[39mModelCheckpoint(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEfficientNetB3_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mIMAGE_SIZE[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mSEED\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_m\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mparams[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mm\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_s\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mparams[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ms\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.h5\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     13\u001b[0m                                                 monitor \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_loss\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m     14\u001b[0m                                                 save_best_only \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m     15\u001b[0m                                                 save_weights_only \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m     16\u001b[0m                                                 mode \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmin\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m---> 18\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_dataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     19\u001b[0m \u001b[43m                    \u001b[49m\u001b[43msteps_per_epoch\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mSTEPS_PER_EPOCH\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     20\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mEPOCHS\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     21\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43mcheckpoint\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     22\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mval_dataset\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py:64\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     62\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     63\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 64\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     65\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m     66\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py:1384\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1377\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[0;32m   1378\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m   1379\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[0;32m   1380\u001b[0m     step_num\u001b[38;5;241m=\u001b[39mstep,\n\u001b[0;32m   1381\u001b[0m     batch_size\u001b[38;5;241m=\u001b[39mbatch_size,\n\u001b[0;32m   1382\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m   1383\u001b[0m   callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1384\u001b[0m   tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1385\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[0;32m   1386\u001b[0m     context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    912\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    914\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 915\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    917\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    918\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:947\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    944\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m    945\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[0;32m    946\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[1;32m--> 947\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stateless_fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)  \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[0;32m    948\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stateful_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    949\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[0;32m    950\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[0;32m    951\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:2956\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2953\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m   2954\u001b[0m   (graph_function,\n\u001b[0;32m   2955\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[1;32m-> 2956\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2957\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:1853\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1849\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1850\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1851\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1852\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1853\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1854\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcancellation_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcancellation_manager\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m   1855\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1856\u001b[0m     args,\n\u001b[0;32m   1857\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1858\u001b[0m     executing_eagerly)\n\u001b[0;32m   1859\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:499\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    497\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _InterpolateFunctionError(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    498\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m cancellation_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 499\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    500\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    501\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_num_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    502\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    503\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    504\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    505\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    506\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m    507\u001b[0m         \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msignature\u001b[38;5;241m.\u001b[39mname),\n\u001b[0;32m    508\u001b[0m         num_outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    511\u001b[0m         ctx\u001b[38;5;241m=\u001b[39mctx,\n\u001b[0;32m    512\u001b[0m         cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_manager)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 54\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     55\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     57\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "seed = 42\n",
    "seed_everything(seed)\n",
    "train, valid = train_test_split(train_filenames, shuffle = True, random_state = seed)\n",
    "train_dataset = get_dataset(train, training=True)\n",
    "train_dataset = train_dataset.map(lambda posting_id, image, label_group, matches: (image, label_group))\n",
    "val_dataset = get_dataset(valid)\n",
    "val_dataset = val_dataset.map(lambda posting_id, image, label_group, matches: (image, label_group))\n",
    "tf.keras.backend.clear_session()\n",
    "\n",
    "model = get_model(params, N_CLASSES, IMAGE_SIZE, cosine_lr_fn)\n",
    "# Model checkpoint\n",
    "checkpoint = tf.keras.callbacks.ModelCheckpoint(f\"EfficientNetB3_{IMAGE_SIZE[0]}_{SEED}_m{params['m']}_s{params['s']}.h5\",\n",
    "                                                monitor = 'val_loss',\n",
    "                                                save_best_only = True,\n",
    "                                                save_weights_only = True,\n",
    "                                                mode = 'min')\n",
    "\n",
    "history = model.fit(train_dataset,\n",
    "                    steps_per_epoch = STEPS_PER_EPOCH,\n",
    "                    epochs = EPOCHS,\n",
    "                    callbacks = [checkpoint],\n",
    "                    validation_data = val_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87ae2258-899b-4047-aaed-1a177ff8d69c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
