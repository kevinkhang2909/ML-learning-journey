{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f3a010a0-1e28-42e1-be3b-5dbe8ab3f85c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "from func import ShopeeDataset, device, torch, np, f1_score_cal, display_df, path, path_img, get_data\n",
    "import tensorflow as tf\n",
    "import efficientnet.keras as efn\n",
    "import math\n",
    "from sklearn.neighbors import NearestNeighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d95538fa-3b1c-423d-aa3f-0e5580286462",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>posting_id</th>\n",
       "      <th>image</th>\n",
       "      <th>image_phash</th>\n",
       "      <th>title</th>\n",
       "      <th>label_group</th>\n",
       "      <th>filepath</th>\n",
       "      <th>target</th>\n",
       "      <th>title_edit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>train_129225211</td>\n",
       "      <td>0000a68812bc7e98c42888dfb1c07da0.jpg</td>\n",
       "      <td>94974f937d4c2433</td>\n",
       "      <td>Paper Bag Victoria Secret</td>\n",
       "      <td>249114794</td>\n",
       "      <td>/Users/kevin/OneDrive - Seagroup/computer_viso...</td>\n",
       "      <td>[train_129225211, train_2278313361]</td>\n",
       "      <td>paper bag victoria secret</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>train_3386243561</td>\n",
       "      <td>00039780dfc94d01db8676fe789ecd05.jpg</td>\n",
       "      <td>af3f9460c2838f0f</td>\n",
       "      <td>Double Tape 3M VHB 12 mm x 4,5 m ORIGINAL / DO...</td>\n",
       "      <td>2937985045</td>\n",
       "      <td>/Users/kevin/OneDrive - Seagroup/computer_viso...</td>\n",
       "      <td>[train_3386243561, train_3423213080]</td>\n",
       "      <td>double tape 3m vhb 12 mm x 4,5 m original / do...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>train_2288590299</td>\n",
       "      <td>000a190fdd715a2a36faed16e2c65df7.jpg</td>\n",
       "      <td>b94cb00ed3e50f78</td>\n",
       "      <td>Maling TTS Canned Pork Luncheon Meat 397 gr</td>\n",
       "      <td>2395904891</td>\n",
       "      <td>/Users/kevin/OneDrive - Seagroup/computer_viso...</td>\n",
       "      <td>[train_2288590299, train_3803689425]</td>\n",
       "      <td>maling tts canned pork luncheon meat 397 gr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>train_2406599165</td>\n",
       "      <td>00117e4fc239b1b641ff08340b429633.jpg</td>\n",
       "      <td>8514fc58eafea283</td>\n",
       "      <td>Daster Batik Lengan pendek - Motif Acak / Camp...</td>\n",
       "      <td>4093212188</td>\n",
       "      <td>/Users/kevin/OneDrive - Seagroup/computer_viso...</td>\n",
       "      <td>[train_3342059966, train_2406599165]</td>\n",
       "      <td>daster batik lengan pendek - motif acak / camp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>train_3369186413</td>\n",
       "      <td>00136d1cf4edede0203f32f05f660588.jpg</td>\n",
       "      <td>a6f319f924ad708c</td>\n",
       "      <td>Nescafe \\xc3\\x89clair Latte 220ml</td>\n",
       "      <td>3648931069</td>\n",
       "      <td>/Users/kevin/OneDrive - Seagroup/computer_viso...</td>\n",
       "      <td>[train_3369186413, train_921438619]</td>\n",
       "      <td>nescafe \\xc3\\x89clair latte 220ml</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         posting_id                                 image       image_phash  \\\n",
       "0   train_129225211  0000a68812bc7e98c42888dfb1c07da0.jpg  94974f937d4c2433   \n",
       "1  train_3386243561  00039780dfc94d01db8676fe789ecd05.jpg  af3f9460c2838f0f   \n",
       "2  train_2288590299  000a190fdd715a2a36faed16e2c65df7.jpg  b94cb00ed3e50f78   \n",
       "3  train_2406599165  00117e4fc239b1b641ff08340b429633.jpg  8514fc58eafea283   \n",
       "4  train_3369186413  00136d1cf4edede0203f32f05f660588.jpg  a6f319f924ad708c   \n",
       "\n",
       "                                               title  label_group  \\\n",
       "0                          Paper Bag Victoria Secret    249114794   \n",
       "1  Double Tape 3M VHB 12 mm x 4,5 m ORIGINAL / DO...   2937985045   \n",
       "2        Maling TTS Canned Pork Luncheon Meat 397 gr   2395904891   \n",
       "3  Daster Batik Lengan pendek - Motif Acak / Camp...   4093212188   \n",
       "4                  Nescafe \\xc3\\x89clair Latte 220ml   3648931069   \n",
       "\n",
       "                                            filepath  \\\n",
       "0  /Users/kevin/OneDrive - Seagroup/computer_viso...   \n",
       "1  /Users/kevin/OneDrive - Seagroup/computer_viso...   \n",
       "2  /Users/kevin/OneDrive - Seagroup/computer_viso...   \n",
       "3  /Users/kevin/OneDrive - Seagroup/computer_viso...   \n",
       "4  /Users/kevin/OneDrive - Seagroup/computer_viso...   \n",
       "\n",
       "                                 target  \\\n",
       "0   [train_129225211, train_2278313361]   \n",
       "1  [train_3386243561, train_3423213080]   \n",
       "2  [train_2288590299, train_3803689425]   \n",
       "3  [train_3342059966, train_2406599165]   \n",
       "4   [train_3369186413, train_921438619]   \n",
       "\n",
       "                                          title_edit  \n",
       "0                          paper bag victoria secret  \n",
       "1  double tape 3m vhb 12 mm x 4,5 m original / do...  \n",
       "2        maling tts canned pork luncheon meat 397 gr  \n",
       "3  daster batik lengan pendek - motif acak / camp...  \n",
       "4                  nescafe \\xc3\\x89clair latte 220ml  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# input\n",
    "df = get_data(path / 'train.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2ef29217-40f2-4741-860a-d8ef60f4b838",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_paths = df.filepath.unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5e5afcac-93c6-4fd7-bae5-af96332ae1af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(s,m,bottleneck):\n",
    "\n",
    "    ''' This function creates our model, we can choose from B0-B7 as our bottle neck model  '''\n",
    "\n",
    "    margin = ArcMarginProduct(\n",
    "        n_classes = N_CLASSES, \n",
    "        s = s, \n",
    "        m = m, \n",
    "        name='head/arc_margin', \n",
    "        dtype='float32'\n",
    "        )\n",
    "\n",
    "    inp = tf.keras.layers.Input(shape = (*IMAGE_SIZE, 3), name = 'inp1')\n",
    "    label = tf.keras.layers.Input(shape = (), name = 'inp2')\n",
    "    \n",
    "    \n",
    "    if bottleneck=='b0':\n",
    "        x = efn.EfficientNetB0(weights = 'imagenet', include_top = False)(inp)           \n",
    "    \n",
    "    elif bottleneck=='b1':\n",
    "        x = efn.EfficientNetB1(weights = 'imagenet', include_top = False)(inp)\n",
    "        \n",
    "    elif bottleneck=='b3':\n",
    "        x = efn.EfficientNetB3(weights = 'imagenet', include_top = False)(inp)\n",
    "        \n",
    "    elif bottleneck=='b5':\n",
    "        x = efn.EfficientNetB5(weights = 'imagenet', include_top = False)(inp)\n",
    "    \n",
    "    elif bottleneck=='b7':\n",
    "        x = efn.EfficientNetB7(weights = 'imagenet', include_top = False)(inp)\n",
    "        \n",
    "    x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
    "    x = margin([x, label])\n",
    "    \n",
    "    output = tf.keras.layers.Softmax(dtype='float32')(x)\n",
    "\n",
    "    model = tf.keras.models.Model(inputs = [inp, label], outputs = [output])\n",
    "\n",
    "    opt = tf.keras.optimizers.Adam(learning_rate = LR)\n",
    "\n",
    "    model.compile(\n",
    "        optimizer = opt,\n",
    "        loss = [tf.keras.losses.SparseCategoricalCrossentropy()],\n",
    "        metrics = [tf.keras.metrics.SparseCategoricalAccuracy()]\n",
    "        ) \n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61a0ea7c-db99-461a-8718-88574ce5b87d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_call(s,m,model_n,epochs):\n",
    "    \n",
    "    K.clear_session()\n",
    "    s=s\n",
    "    m=m\n",
    "    model = get_model(s,m,model_n)\n",
    "\n",
    "    # Model checkpoint\n",
    "    checkpoint = tf.keras.callbacks.ModelCheckpoint(f'EfficientNet_{model_n}_{s}_{m}_{IMAGE_SIZE[0]}_{SEED}.h5', \n",
    "                                                monitor = 'val_loss', \n",
    "                                                verbose = VERBOSE, \n",
    "                                                save_best_only = True,\n",
    "                                                save_weights_only = True, \n",
    "                                                mode = 'min')\n",
    "    \n",
    "    #Early Stopping\n",
    "    early =tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=3)\n",
    "    \n",
    "    EPOCHS=epochs\n",
    "\n",
    "    #Creating Model\n",
    "    history = model.fit(train_dataset,\n",
    "                    steps_per_epoch = STEPS_PER_EPOCH,\n",
    "                    epochs = EPOCHS,\n",
    "                    callbacks = [checkpoint, get_lr_callback(),early], \n",
    "                    validation_data = val_dataset,\n",
    "                    verbose = VERBOSE)\n",
    "    \n",
    "    \n",
    "    #Plotting the model accuracy, loss after compilation\n",
    "\n",
    "    plt.plot(history.history['sparse_categorical_accuracy'])\n",
    "    plt.plot(history.history['val_sparse_categorical_accuracy'])\n",
    "    plt.title('Sparse Categorical Accuracy')\n",
    "    plt.ylabel('accuracy')\n",
    "    plt.xlabel('epochs')\n",
    "    plt.legend(['train', 'val'], loc='upper left')\n",
    "    plt.show()\n",
    "    # summarize history for loss\n",
    "    plt.plot(history.history['loss'])\n",
    "    plt.plot(history.history['val_loss'])\n",
    "    plt.title('Model loss')\n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'val'], loc='upper left')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "s=15\n",
    "m=0.0001 \n",
    "model='b3'\n",
    "epochs=50\n",
    "model = model_call(s,m,model,epochs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
