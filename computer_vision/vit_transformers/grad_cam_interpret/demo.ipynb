{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from PIL import Image\n",
    "from datasets import load_dataset\n",
    "from transformers import ViTForImageClassification\n",
    "from torchvision import transforms\n",
    "from pytorch_grad_cam.utils.model_targets import ClassifierOutputTarget\n",
    "from pytorch_grad_cam import run_dff_on_image\n",
    "\n",
    "from modules import reshape_vit_huggingface, print_top_categories, run_grad_cam_on_image"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "dataset = load_dataset(\"huggingface/cats-image\")\n",
    "image = dataset[\"test\"][\"image\"][0]\n",
    "image"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# input\n",
    "model_pretrain = 'google/vit-large-patch32-384'\n",
    "image_size = (384, 384)\n",
    "\n",
    "# model config\n",
    "model = ViTForImageClassification.from_pretrained(model_pretrain)\n",
    "category_dict = dict((v, k) for k, v in model.config.id2label.items())\n",
    "\n",
    "# image input\n",
    "image_resized = image.resize(image_size)\n",
    "tensor_resized = transforms.ToTensor()(image_resized)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Deep Feature Factorization, and those sneaky LayerNorm layers\n",
    "- that does Non Negative Matrix Factorization on the features to cluster them into several feature concepts\n",
    "- Every concept then gets a feature representation. We can associate every concept with the categories, by running the classifier on each of these representations, and displaying that in a legend next to the image\n",
    "\n",
    "Ref: Tutorials [DFF](https://jacobgil.github.io/pytorch-gradcam-book/Deep%20Feature%20Factorizations.html)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# dff config\n",
    "target_layer_dff = model.vit.layernorm\n",
    "image_dff = run_dff_on_image(model=model,\n",
    "                             target_layer=target_layer_dff,\n",
    "                             classifier=model.classifier,\n",
    "                             img_pil=image_resized,\n",
    "                             img_tensor=tensor_resized,\n",
    "                             reshape_transform=reshape_vit_huggingface,\n",
    "                             n_components=4,\n",
    "                             top_k=2)\n",
    "display(Image.fromarray(image_dff))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Grad-cam"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# grad_cam config\n",
    "targets_for_gradcam = [ClassifierOutputTarget(category_dict[\"Egyptian cat\"]),\n",
    "                       ClassifierOutputTarget(category_dict[\"remote control, remote\"])]\n",
    "target_layer_gradcam = model.vit.encoder.layer[-2].output\n",
    "image_grad_cam = run_grad_cam_on_image(model=model,\n",
    "                                       target_layer=target_layer_gradcam,\n",
    "                                       targets_for_gradcam=targets_for_gradcam,\n",
    "                                       input_tensor=tensor_resized,\n",
    "                                       input_image=image_resized,\n",
    "                                       reshape_transform=reshape_vit_huggingface)\n",
    "display(Image.fromarray(image_grad_cam))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print_top_categories(model, tensor_resized)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# input\n",
    "model_pretrain = 'google/vit-base-patch16-224-in21k'\n",
    "image_size = (224, 224)\n",
    "# model_pretrain = 'google/vit-large-patch32-384'\n",
    "# image_size = (384, 384)\n",
    "\n",
    "# model config\n",
    "model = ViTForImageClassification.from_pretrained(model_pretrain)\n",
    "category_dict = dict((v, k) for k, v in model.config.id2label.items())\n",
    "\n",
    "# image input\n",
    "image_resized = image.resize(image_size)\n",
    "tensor_resized = transforms.ToTensor()(image_resized)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# dff config\n",
    "target_layer_dff = model.vit.layernorm\n",
    "image_dff = run_dff_on_image(model=model,\n",
    "                             target_layer=target_layer_dff,\n",
    "                             classifier=model.classifier,\n",
    "                             img_pil=image_resized,\n",
    "                             img_tensor=tensor_resized,\n",
    "                             reshape_transform=reshape_vit_huggingface,\n",
    "                             n_components=4,\n",
    "                             top_k=2)\n",
    "display(Image.fromarray(image_dff))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# grad_cam config\n",
    "targets_for_gradcam = [ClassifierOutputTarget(category_dict[\"Egyptian cat\"]),\n",
    "                       ClassifierOutputTarget(category_dict[\"remote control, remote\"])]\n",
    "target_layer_gradcam = model.vit.encoder.layer[-2].output\n",
    "image_grad_cam = run_grad_cam_on_image(model=model,\n",
    "                                       target_layer=target_layer_gradcam,\n",
    "                                       targets_for_gradcam=targets_for_gradcam,\n",
    "                                       input_tensor=tensor_resized,\n",
    "                                       input_image=image_resized,\n",
    "                                       reshape_transform=reshape_vit_huggingface)\n",
    "display(Image.fromarray(image_grad_cam))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
