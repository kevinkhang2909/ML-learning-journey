{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kevinkhang2909/ML-learning-journey/blob/main/nlp/markov_chain.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vLT38qfcJlml",
        "outputId": "b7bb709a-c522-487a-a87d-1666a096b63b"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_4RY7dvUJdbi",
        "outputId": "5b050f0f-4693-474b-c808-ab56fc0034a4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "import re\n",
        "import string\n",
        "import random\n",
        "from tqdm import tqdm\n",
        "from pathlib import Path\n",
        "from zipfile import ZipFile\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "\n",
        "from nltk.tokenize import word_tokenize"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "file_name = '/content/drive/MyDrive/Colab Notebooks/data/sherlock.zip'\n",
        "  \n",
        "with ZipFile(file_name, 'r') as zip:\n",
        "    zip.extractall('/content/')"
      ],
      "metadata": {
        "id": "IsQ2lYNhKgtp"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "story_path = Path('/content/sherlock/sherlock')\n",
        "files = list(story_path.glob('*.txt'))\n",
        "\n",
        "stories = []\n",
        "for file in tqdm(files):\n",
        "    with open(file) as f:\n",
        "        for line in f:\n",
        "            line = line.strip()\n",
        "            if line == '----------': \n",
        "                break\n",
        "            if line != '': \n",
        "                stories.append(line)\n",
        "\n",
        "print(len(stories))\n",
        "stories[:5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3fwPI21FJlHy",
        "outputId": "6ce4d066-fb5c-4218-c83f-15b462f863f9"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 67/67 [00:00<00:00, 295.01it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "215021\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['THE ADVENTURE OF THE BLUE CARBUNCLE',\n",
              " 'Arthur Conan Doyle',\n",
              " 'I had called upon my friend Sherlock Holmes upon the second morning',\n",
              " 'after Christmas, with the intention of wishing him the compliments of',\n",
              " 'the season. He was lounging upon the sofa in a purple dressing-gown,']"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cleaned_stories = []\n",
        "for line in tqdm(stories):\n",
        "    line = line.lower()\n",
        "    line = re.sub(r\"[,.\\\"\\'!@#$%^&*(){}?/;`~:<>+=-\\\\]\", \"\", line)\n",
        "    tokens = word_tokenize(line)\n",
        "    words = [word for word in tokens if word.isalpha()]\n",
        "    cleaned_stories += words\n",
        "\n",
        "print(len(cleaned_stories))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N3d46WliLWGX",
        "outputId": "a6fb81fa-d93e-4321-b13c-9ee489f526fc"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 215021/215021 [00:36<00:00, 5903.78it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2332247\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cleaned_stories[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UFzD04REL_0l",
        "outputId": "9c0bea91-6643-43b2-a44d-09e95b7e23a8"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['the',\n",
              " 'adventure',\n",
              " 'of',\n",
              " 'the',\n",
              " 'blue',\n",
              " 'carbuncle',\n",
              " 'arthur',\n",
              " 'conan',\n",
              " 'doyle',\n",
              " 'i']"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def make_markov_model(cleaned_stories, n_gram=2):\n",
        "    markov_model = {}\n",
        "    for i in tqdm(range(len(cleaned_stories)-n_gram-1), desc='token to nested dict'):\n",
        "        curr_state, next_state = \"\", \"\"\n",
        "        for j in range(n_gram):\n",
        "            curr_state += cleaned_stories[i + j] + \" \"\n",
        "            next_state += cleaned_stories[i + j + n_gram] + \" \"\n",
        "        curr_state = curr_state[:-1]  # remove space\n",
        "        next_state = next_state[:-1]  # remove space\n",
        "        if curr_state not in markov_model:\n",
        "            markov_model[curr_state] = {}\n",
        "            markov_model[curr_state][next_state] = 1\n",
        "        else:\n",
        "            if next_state in markov_model[curr_state]:\n",
        "                markov_model[curr_state][next_state] += 1\n",
        "            else:\n",
        "                markov_model[curr_state][next_state] = 1\n",
        "    \n",
        "    for curr_state, transition in tqdm(markov_model.items(), desc='prob'):\n",
        "        total = sum(transition.values())\n",
        "        for state, count in transition.items():\n",
        "            markov_model[curr_state][state] = count/total\n",
        "        \n",
        "    return markov_model"
      ],
      "metadata": {
        "id": "gVkiKkztMSZV"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "markov_model = make_markov_model(cleaned_stories)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eqnW97M1Mdgz",
        "outputId": "7f3d6e88-0e8e-4e82-993a-fd215fcdffc9"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "token to nested dict: 100%|██████████| 2332244/2332244 [00:10<00:00, 216503.85it/s]\n",
            "prob: 100%|██████████| 208717/208717 [00:00<00:00, 483717.93it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'number of states = {len(markov_model.keys())}')\n",
        "print(markov_model['the game'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fVQ7hWUNMifY",
        "outputId": "502bae51-37ea-4484-a9e7-cb2b0d44f2a8"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "number of states = 208717\n",
            "{'for the': 0.036036036036036036, 'is up': 0.06306306306306306, 'is and': 0.036036036036036036, 'was afoot': 0.036036036036036036, 'would have': 0.036036036036036036, 'in their': 0.036036036036036036, 'your letter': 0.02702702702702703, 'for all': 0.06306306306306306, 'i am': 0.02702702702702703, 'now count': 0.02702702702702703, 'worth it': 0.02702702702702703, 'you are': 0.02702702702702703, 'my own': 0.02702702702702703, 'at any': 0.02702702702702703, 'mr holmes': 0.02702702702702703, 'ay whats': 0.02702702702702703, 'my friend': 0.02702702702702703, 'fairly by': 0.02702702702702703, 'is not': 0.02702702702702703, 'was not': 0.02702702702702703, 'was in': 0.02702702702702703, 'is hardly': 0.02702702702702703, 'was whist': 0.036036036036036036, 'was up': 0.09009009009009009, 'in that': 0.036036036036036036, 'the lack': 0.036036036036036036, 'is afoot': 0.036036036036036036, 'may wander': 0.02702702702702703, 'now a': 0.02702702702702703}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_story(markov_model, limit=100, start='my god'):\n",
        "    n = 0\n",
        "    curr_state = start\n",
        "    next_state = None\n",
        "    story = \"\"\n",
        "    story += curr_state + \" \"\n",
        "    while n < limit:\n",
        "        next_state = random.choices(list(markov_model[curr_state].keys()),\n",
        "                                    list(markov_model[curr_state].values()))\n",
        "        curr_state = next_state[0]\n",
        "        story += curr_state + \" \"\n",
        "        n += 1\n",
        "    return story"
      ],
      "metadata": {
        "id": "G4FrA2F7Mow1"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(20):\n",
        "    print(f\"{i}. {generate_story(markov_model, start='dear holmes', limit=8)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wuyvSXz0Msyq",
        "outputId": "62309eb5-5ca2-482f-cbaa-7a63b27b9c9f"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0. dear holmes what do you think the quarrel between the hours of the night i am staying with \n",
            "1. dear holmes i have my dooties just the one candle that was my singular interview with the lady \n",
            "2. dear holmes i fear that you were never in the least if the man or men who have \n",
            "3. dear holmes he has not been for my attendance when i arrived at baker street but i can \n",
            "4. dear holmes that i often wonder it can not be bought he will get our work done before \n",
            "5. dear holmes what do you imagine i am telling you the story is said that there are business \n",
            "6. dear holmes i exclaimed i could not tell you as man to fall foul of see here he \n",
            "7. dear holmes that i should be here he kept his distance until the curve of the address of \n",
            "8. dear holmes said i as i passed his handkerchief over his brow brother morris and may they not \n",
            "9. dear holmes you are enough to find out how could i leave the tray form the message and \n",
            "10. dear holmes oh yes he is ever ready with a sinister smile the lights of the same week \n",
            "11. dear holmes what do you think then definitely that barker was in the library and the fact that \n",
            "12. dear holmes i fear my dear watson said he we ought to tell you yes we have been \n",
            "13. dear holmes that i owe a very humble apology to me said he i hope i didnt harm \n",
            "14. dear holmes said i you must understand dr watson that this is particularly so in the hands of \n",
            "15. dear holmes i have acted how i have finished at the you would care to interest you mr \n",
            "16. dear holmes oh yes he will get no rest from it what conclusion would it suggest to your \n",
            "17. dear holmes i exclaimed perhaps one of those who invented that writing might be and i was always \n",
            "18. dear holmes you are ready to devote my life to me and he poor fellow can be of \n",
            "19. dear holmes am i a wandering american with a wonderful fine woman in every respect with that of \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "generate_story(markov_model, start='the case', limit=100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 140
        },
        "id": "O4Yn-gZaMs5c",
        "outputId": "2be0e453-a617-4551-eaff-3dc160f94ad3"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'the case which promise to make the matter at what hour was not long for this affair has been most deplorably handled i feel that the lady had hurriedly ransacked them before deciding that question i trust that they do not always sufficient and you can remember tadpole phelps who was in vain that i asked the worst what can it mean it means disgrace as well but he was at work and yet i thought you had then been a pause the candle held against the glass work in afghanistan coming on the father of this lad tend to some end or else secure her rights would change from his dressing gown and exposed as high as the elbow where you are and where to hide to get you i know what is that holmes the finding of the bride lord st simon had by sheer horror and exhaustion there was a savage wild animal loose about the place belonged to prosaic and yet as clearly as far as it goes that is her ring it may be a marriage between us james and i am in touch with every development upon the high road and when my companion who had '"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2tTzcqpvMxQ1"
      },
      "execution_count": 12,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 2
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython2",
      "version": "2.7.6"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}