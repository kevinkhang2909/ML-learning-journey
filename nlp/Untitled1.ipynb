{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "419b9647-87fa-43f0-a4be-c8f10be74d94",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "451e20e2-0953-4123-b47a-3b7d2dc13fd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 3)\n"
     ]
    }
   ],
   "source": [
    "data = np.array([[1., 3., 2.]])\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "255f1466-a010-4991-895a-c74dc0a62748",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 1])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.Tensor([1., 3., 2.]).reshape((3, 1)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "b365e811-ab72-4ebd-84ad-2d0d83069774",
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "was expecting embedding dimension of 2, but got 1",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mAssertionError\u001B[0m                            Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[57], line 4\u001B[0m\n\u001B[1;32m      2\u001B[0m num_heads, embed_dim \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m, \u001B[38;5;241m2\u001B[39m\n\u001B[1;32m      3\u001B[0m multihead_attn \u001B[38;5;241m=\u001B[39m nn\u001B[38;5;241m.\u001B[39mMultiheadAttention(embed_dim, num_heads)\n\u001B[0;32m----> 4\u001B[0m attn_output, attn_output_weights \u001B[38;5;241m=\u001B[39m \u001B[43mmultihead_attn\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdata\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdata\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdata\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/.conda/envs/haha/lib/python3.9/site-packages/torch/nn/modules/module.py:1130\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *input, **kwargs)\u001B[0m\n\u001B[1;32m   1126\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1127\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1128\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1129\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1130\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1131\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[1;32m   1132\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "File \u001B[0;32m~/.conda/envs/haha/lib/python3.9/site-packages/torch/nn/modules/activation.py:1153\u001B[0m, in \u001B[0;36mMultiheadAttention.forward\u001B[0;34m(self, query, key, value, key_padding_mask, need_weights, attn_mask, average_attn_weights)\u001B[0m\n\u001B[1;32m   1142\u001B[0m     attn_output, attn_output_weights \u001B[38;5;241m=\u001B[39m F\u001B[38;5;241m.\u001B[39mmulti_head_attention_forward(\n\u001B[1;32m   1143\u001B[0m         query, key, value, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39membed_dim, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mnum_heads,\n\u001B[1;32m   1144\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39min_proj_weight, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39min_proj_bias,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   1150\u001B[0m         q_proj_weight\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mq_proj_weight, k_proj_weight\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mk_proj_weight,\n\u001B[1;32m   1151\u001B[0m         v_proj_weight\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mv_proj_weight, average_attn_weights\u001B[38;5;241m=\u001B[39maverage_attn_weights)\n\u001B[1;32m   1152\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1153\u001B[0m     attn_output, attn_output_weights \u001B[38;5;241m=\u001B[39m \u001B[43mF\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmulti_head_attention_forward\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   1154\u001B[0m \u001B[43m        \u001B[49m\u001B[43mquery\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkey\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mvalue\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43membed_dim\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mnum_heads\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1155\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43min_proj_weight\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43min_proj_bias\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1156\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbias_k\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbias_v\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43madd_zero_attn\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1157\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdropout\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mout_proj\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mweight\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mout_proj\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbias\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1158\u001B[0m \u001B[43m        \u001B[49m\u001B[43mtraining\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtraining\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1159\u001B[0m \u001B[43m        \u001B[49m\u001B[43mkey_padding_mask\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mkey_padding_mask\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mneed_weights\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mneed_weights\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1160\u001B[0m \u001B[43m        \u001B[49m\u001B[43mattn_mask\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mattn_mask\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43maverage_attn_weights\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43maverage_attn_weights\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1161\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbatch_first \u001B[38;5;129;01mand\u001B[39;00m is_batched:\n\u001B[1;32m   1162\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m attn_output\u001B[38;5;241m.\u001B[39mtranspose(\u001B[38;5;241m1\u001B[39m, \u001B[38;5;241m0\u001B[39m), attn_output_weights\n",
      "File \u001B[0;32m~/.conda/envs/haha/lib/python3.9/site-packages/torch/nn/functional.py:5046\u001B[0m, in \u001B[0;36mmulti_head_attention_forward\u001B[0;34m(query, key, value, embed_dim_to_check, num_heads, in_proj_weight, in_proj_bias, bias_k, bias_v, add_zero_attn, dropout_p, out_proj_weight, out_proj_bias, training, key_padding_mask, need_weights, attn_mask, use_separate_proj_weight, q_proj_weight, k_proj_weight, v_proj_weight, static_k, static_v, average_attn_weights)\u001B[0m\n\u001B[1;32m   5044\u001B[0m tgt_len, bsz, embed_dim \u001B[38;5;241m=\u001B[39m query\u001B[38;5;241m.\u001B[39mshape\n\u001B[1;32m   5045\u001B[0m src_len, _, _ \u001B[38;5;241m=\u001B[39m key\u001B[38;5;241m.\u001B[39mshape\n\u001B[0;32m-> 5046\u001B[0m \u001B[38;5;28;01massert\u001B[39;00m embed_dim \u001B[38;5;241m==\u001B[39m embed_dim_to_check, \\\n\u001B[1;32m   5047\u001B[0m     \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mwas expecting embedding dimension of \u001B[39m\u001B[38;5;132;01m{\u001B[39;00membed_dim_to_check\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m, but got \u001B[39m\u001B[38;5;132;01m{\u001B[39;00membed_dim\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m   5048\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(embed_dim, torch\u001B[38;5;241m.\u001B[39mTensor):\n\u001B[1;32m   5049\u001B[0m     \u001B[38;5;66;03m# embed_dim can be a tensor when JIT tracing\u001B[39;00m\n\u001B[1;32m   5050\u001B[0m     head_dim \u001B[38;5;241m=\u001B[39m embed_dim\u001B[38;5;241m.\u001B[39mdiv(num_heads, rounding_mode\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtrunc\u001B[39m\u001B[38;5;124m'\u001B[39m)\n",
      "\u001B[0;31mAssertionError\u001B[0m: was expecting embedding dimension of 2, but got 1"
     ]
    }
   ],
   "source": [
    "data = torch.Tensor([1., 3., 2.]).reshape((3, 1))\n",
    "num_heads, embed_dim = 1, 2\n",
    "multihead_attn = nn.MultiheadAttention(embed_dim, num_heads)\n",
    "attn_output, attn_output_weights = multihead_attn(data, data, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a970304f-19a9-4ba5-b5fa-1c6a4d7061d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 2)\n",
      "(3, 2)\n",
      "(3, 2)\n"
     ]
    }
   ],
   "source": [
    "q = np.array([[0.4,  0.3],\n",
    "              [-0.1, -0.1],\n",
    "              [ 0.2, -0.1]])\n",
    "k = np.array([[ 0.1,  0.2 ],\n",
    "              [-0.3, -0.4],\n",
    "              [-0.1,  0.2]])\n",
    "v = np.array([[-0.2,  0.1],\n",
    "              [-0.4,  0.2],\n",
    "              [0.4, -0.6]])\n",
    "\n",
    "print(q.shape)\n",
    "print(k.shape)\n",
    "print(v.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e914b831-01db-4c4d-a4f7-1a4733bf67b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 2)\n",
      "[[-1.  -0.6]]\n",
      "[[-0.6 -0.5]]\n"
     ]
    }
   ],
   "source": [
    "q_value = np.dot(data, q)\n",
    "k_value = np.dot(data, k)\n",
    "v_value = np.dot(data, v)\n",
    " \n",
    "print(q_value)\n",
    "print(k_value)\n",
    "print(v_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "be437912-fc0e-4e81-8151-c2bb6613bd4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.]])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def softmax(x):\n",
    "    e_x = np.exp(x - np.max(x))\n",
    "    return e_x / e_x.sum()\n",
    "\n",
    "alpha = softmax(np.dot(k_value, q_value.T))\n",
    "alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "056fdb07-31a6-4b05-ab6a-25e0f3ee11ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.38]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.dot(k_value, q_value.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c9fba36c-8ffb-4769-bcc5-4daf8837f58d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.6 -0.5]]\n"
     ]
    }
   ],
   "source": [
    "context_vector = alpha * v_value\n",
    "print(context_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "8b7b5a45-6cf4-412c-9aeb-ca1a17a1eb3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.1 -0.1  0.6]\n",
      " [ 0.9  0.3  0.1]]\n"
     ]
    }
   ],
   "source": [
    "o = np.array([[ 0.1, -0.1,  0.6 ],\n",
    "              [ 0.9,  0.3,  0.1 ]])\n",
    "print(o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "fed161be-3e19-4a46-bd80-6599ffb41230",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.51 -0.09 -0.41]]\n"
     ]
    }
   ],
   "source": [
    "output = np.dot(context_vector, o)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e69ce4e-c00f-48a8-b83e-67b4bc131650",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
